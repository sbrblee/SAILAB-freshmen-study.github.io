---
layout: post
title: "[ë…¼ë¬¸ë¦¬ë·°] XAI Evaluation"
date: 2024-03-29 00:00:00 +0900
author: Yeonjea Kim
categories: ["XAI", "Evaluation Methods"]
use_math: true
---
**XAI Evaluation**

ì„¤ëª… ê°€ëŠ¥ ì¸ê³µì§€ëŠ¥(Explainable AI, XAI) ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´ì •ë¦¬ : XAI í‰ê°€ëŠ” ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ? í™œìš©í•  ìˆ˜ ìˆëŠ” ê°œë…ê³¼ ë°©ë²•ì€ ì–´ë–¤ ê²ƒì´ ìˆì„ê¹Œ?

ì´ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì•„ë˜ ë…¼ë¬¸ì„ ë‹¤ë£¹ë‹ˆë‹¤.

Meike Nauta, et al., (2023) XAI Evaluation - From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI

ì›¹ ë·° - [https://dl.acm.org/doi/10.1145/3583558](https://dl.acm.org/doi/10.1145/3583558)

arxiv - [https://arxiv.org/abs/2201.08164](https://arxiv.org/abs/2201.08164)

ì œê³µì¤‘ì¸ ì‚¬ì´íŠ¸ë¥¼ ë‘˜ëŸ¬ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤ - [https://utwente-dmb.github.io/xai-papers/](https://utwente-dmb.github.io/xai-papers/)

### Summary

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ë³µì¡ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼ XAIì— ëŒ€í•œ í•„ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì¼í™”ì (anecdotal ; ì‚¬ë¡€ë‚˜ ê°œì¸ì  ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ëŠ”) ì¦ê±°ëŠ” í‰ê°€ì— ìˆì–´ í•œê³„ê°€ ìˆì–´ ì •ëŸ‰ì ì¸ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤. 

ë…¼ë¬¸ì—ì„œëŠ” ì„¤ëª…ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê°œë…ì  ì†ì„±ìœ¼ë¡œ Co-12 Explanation Quality Properties ë¥¼ ì†Œê°œí•˜ë©´ì„œ, ê·¸ ê¸°ì¤€ìœ¼ë¡œ 300í¸ ì´ìƒì˜ ë…¼ë¬¸ì„ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ í‰ê°€í•œ ê²°ê³¼ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. 


### Method

#### Categorization of Explainable AI Methods

ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ XAI ë°©ë²•ì„ 6ê°€ì§€ ë””ë©˜ì ¼ìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. 

<img src="https://sbrblee.github.io/SAILAB-freshmen-study.github.io/imgs/2024-03-29-XAI_Evaluation/01.png">

Type of Problem : XAI ê°€ í’€ ìˆ˜ ìˆëŠ” 4 ì¢…ë¥˜ì˜ ë¬¸ì œ

- (i) **Model Explanation** â€“ globally explaining model ğ‘“ through an interpretable, predictive model
- (ii) **Model Inspection** â€“ globally explaining some specific property of model ğ‘“ or its prediction
- (iii) **Outcome Explanation** â€“ explaining an outcome/prediction of ğ‘“ on a particular input instance
- (iv) **Transparent Box Design** â€“ the explanation method is an interpretable model (i.e., ğ‘’ = ğ‘“ ) also making the predictions

Type of Method used to Explain : ëª¨ë¸ì„ ì„¤ëª…í•˜ëŠ” 3 ì¢…ë¥˜ì˜ ë°©ë²•

- i) **Post-hoc explanation** methods (also called reverse engineering): explain an already trained predictive model
- ii) **Interpretability built into the predictive model**, such as white-box models, attention mechanisms or interpretability constraints (e.g. sparsity) included in the training process of the predictive model
- iii) **Supervised explanation training**, where a ground-truth explanation is provided in order to train the model to output an explanation.

#### Evaluation of XAI methods with Co-12 Properties

ë…¼ë¬¸ì—ì„œ ì •ë¦¬í•œ ì„¤ëª… í’ˆì§ˆì˜ ì†ì„±ì…ë‹ˆë‹¤.

<img src="https://sbrblee.github.io/SAILAB-freshmen-study.github.io/imgs/2024-03-29-XAI_Evaluation/02.png">

- 01 Correctness : ì§„ì‹¤ì„±/ì¶©ì‹¤ì„±, ì˜ˆì¸¡ì •í™•ë„ê°€ ì•„ë‹Œ ì„¤ëª…ì •í™•ë„
- 02 Completeness : ëª¨ë¸ f ë¥¼ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€. ì´ìƒì ì¸ ê²ƒì€ â€œthe whole truthâ€
- 03 Consistency : ë™ì¼í•œ ì…ë ¥ì— ë™ì¼í•œ ì„¤ëª…ì„ í•˜ëŠ”ì§€
- 04 Continuity : ë¹„ìŠ·í•œ ì…ë ¥ì— ë¹„ìŠ·í•œ ì„¤ëª…ì„ í•˜ëŠ”ì§€, how continuous (i.e. smooth)
- 05 Contrastivity : ë‹¤ë¥¸ ëŒ€ìƒì´ë‚˜ ì‚¬ê±´ê³¼ ê´€ë ¨í•˜ì—¬ ë¹„êµë¥¼ ìš©ì´í•˜ê²Œ í•˜ëŠ”ì§€
    - ì‚¬ê±´ì„ ì„¤ëª…í•  ë¿ë§Œ ì•„ë‹ˆë¼ "ë°œìƒí•˜ì§€ ì•Šì€ *ë‹¤ë¥¸ ì‚¬ê±´ê³¼ ë¹„êµí•˜ì—¬*" ì„¤ëª…í•´ì•¼í•¨
    - ì„œë¡œ ë‹¤ë¥¸ ëª¨ì§‘ë‹¨ì˜ ë™ì¼í•˜ì§€ ì•Šì€ ì¸ìŠ¤í„´ìŠ¤ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì„¤ëª…ì„ ê°€ì ¸ì•¼í•¨
- 06 Covariate complexity : ì„¤ëª…ì— ì‚¬ìš©ëœ covariates(íŠ¹ì§•) ëŠ” ì¸ê°„ì´ í•´ì„ê°€ëŠ¥í•œì§€
- 07 Compactness : ì¸ê°„ì˜ ì¸ì§€ëŠ¥ë ¥ í•œê³„ë•Œë¬¸ì— ìš”êµ¬ë˜ëŠ” ì†ì„±ìœ¼ë¡œ, ì„¤ëª…ì€ sparse, short and not redundant í•´ì•¼í•¨
- 08 Composition : ì„¤ëª…ë˜ëŠ” *ë‚´ìš©ì´* ì•„ë‹ˆë¼ ì„¤ëª…ë˜ëŠ” *ë°©ì‹ì—* ê´€í•œ ê²ƒ
    - ì„¤ëª…ì´ ì œì‹œë˜ëŠ” ë°©ì‹ì´ 'ëª…í™•ì„±'ì„ ë†’ì¼ ìˆ˜ ìˆë„ë¡ í•´ì•¼í•¨
- 09 Confidence :  certainty ë‚˜ probability ê¸°ì¤€ì´ ìˆëŠ”ì§€
- 10 Context : ì´í•´í•˜ê¸° ì‰¬ìš´ ê³„íšì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆëŠ”ì§€
- 11 Coherence : í•©ë¦¬ì„±, íƒ€ë‹¹ì„± ë° "ì¸ê°„ì˜ ì´ì„±ê³¼ì˜ ì¼ì¹˜"í•˜ëŠ”ì§€
- 12 Controllability : ì‚¬ìš©ìê°€ ì„¤ëª…ì„ ì–´ëŠ ì •ë„ê¹Œì§€ ì œì–´, ìˆ˜ì • ë˜ëŠ” ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ”ì§€

### Experiments

ì €ìëŠ” 300ì—¬ê°œê°€ ë„˜ëŠ” ë…¼ë¬¸ì„ ì¡°ì‚¬í•˜ì—¬ ì‚¬ìš©í•œ ì„¤ëª…ë²•ì„ 6ê°€ì§€ ë””ë©˜ì ¼, Co-12 ì†ì„±ì— ë§ì¶”ì–´ ë¶„ë¥˜í•´ì„œ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë…¼ë¬¸ì„ ì°¾ì•„ë³¼ ìˆ˜ ìˆëŠ” ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. (í˜„ì¬ë„ ë…¼ë¬¸ì€ ê³„ì† ì—…ë°ì´íŠ¸ ë˜ê³  ìˆìœ¼ë©°, ëˆ„êµ¬ë‚˜ ë…¼ë¬¸ì„ ë“±ë¡í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤)

[https://utwente-dmb.github.io/xai-papers/](https://utwente-dmb.github.io/xai-papers/) 

ë…¼ë¬¸ì—ëŠ” ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ Co-12ì¹´í…Œê³ ë¦¬ì™€ - XAI ë°©ë²• - ì‚¬ìš©í•œ ë…¼ë¬¸ë“¤ì„ ì •ë¦¬í•´ë‘ì–´ì„œ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src="https://sbrblee.github.io/SAILAB-freshmen-study.github.io/imgs/2024-03-29-XAI_Evaluation/03.png">

XAI ë°©ë²•ì€ ë•Œë¡œëŠ” ì—¬ëŸ¬ê°€ì§€ Co-12 ì†ì„±ì— ì†í•˜ê¸°ë„ í•˜ë©° ì•„ë˜ í…Œì´ë¸”ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src="https://sbrblee.github.io/SAILAB-freshmen-study.github.io/imgs/2024-03-29-XAI_Evaluation/04.png">

### Discussion & Conclusion

XAI ì˜ ì†ì„±ì„ ë³´ë©´ ë•Œë¡œëŠ” ëª¨ìˆœì´ ë˜ëŠ” ì†ì„±ë„ ì¡´ì¬í•©ë‹ˆë‹¤.

- Coherence vs Correctness : ì¼ê´€ vs ì •í™•
- Completeness vs Compactness : ì™„ì „ vs ê°„ê²°

ë…¼ë¬¸ì€, Co-12 ë¥¼ ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì— í†µí•©í•  ê²ƒì„ ì œì•ˆí•˜ë©°, í‘œì¤€í™”ëœ í‰ê°€ ì§€í‘œì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### [Study] Questions & Discussion

ìŠ¤í„°ë””ì¤‘ì— ë‚˜ì™”ë˜ ë…¼ì˜ ì£¼ì œ ëª‡ê°€ì§€ ì†Œê°œí•©ë‹ˆë‹¤.

- Consistency ì†ì„± ê²½ìš° ìƒì„±ëª¨ë¸ì—ëŠ” ì í•©í•˜ì§€ ì•Šì€ ê²ƒì¸ê°€?
- ë‹¤ì–‘í•œ propertyë“¤ì„ ì–´ë–»ê²Œ aggregationí•  ìˆ˜ ìˆì„ê¹Œ? Propertyê°„ì˜ ìš°ì„  ìˆœìœ„ê°€ ìˆì„ê¹Œ?
- Correctness, Completenessì™€ ê°™ì€ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ì‹œê°ì ìœ¼ë¡œë„ ì¢‹ì€ ì„¤ëª…ì¼ê¹Œ?
- Correctness, Completenessë¥¼ ê·¹ëŒ€í™”í•˜ë©´ ì¢‹ì€ explainerë¥¼ ì–»ì„ ìˆ˜ ìˆì„ê¹Œ?